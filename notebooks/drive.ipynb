{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import onnxruntime as ort\n",
    "from utils.sampling import softmax, multinomial\n",
    "from utils.video import write_video, transpose_and_clip\n",
    "from IPython.display import Image, Video\n",
    "import keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model session\n",
    "options = ort.SessionOptions()\n",
    "options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "provider = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "session = ort.InferenceSession(f'../models/gpt2m.onnx', options, provider)\n",
    "# print shapes\n",
    "input_shapes =  { i.name: (i.shape, i.type) for i in session.get_inputs()  }\n",
    "output_shapes = { i.name: (i.shape, i.type) for i in session.get_outputs() }\n",
    "print('input shapes : ', input_shapes)\n",
    "print('output shapes: ', output_shapes)\n",
    "\n",
    "# load decoder\n",
    "decoder_session = ort.InferenceSession(f'../models/decoder.onnx', options, provider)\n",
    "encoder_session = ort.InferenceSession(f'../models/encoder.onnx', options, provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set constants and define functions\n",
    "TOKENS_PER_FRAME = 129\n",
    "MAX_CONTEXT_SIZE = 20*129\n",
    "BOS_TOKEN        = 1024\n",
    "PIXELS_PER_CHUNK = 16\n",
    "\n",
    "def generate_frame_tokens(session, tokens, override=None):\n",
    "  data = {'input_ids': tokens,\n",
    "          **{f'past_{i}': np.zeros((2, 1, 16, 0, 64), dtype=np.float16) for i in range(24)}\n",
    "          }\n",
    "\n",
    "  data_ortvalue = {}\n",
    "  for k in data:\n",
    "      data_ortvalue[k] = ort.OrtValue.ortvalue_from_numpy(data[k], 'cuda', 0)\n",
    "\n",
    "  io_binding = session.io_binding()\n",
    "  for k in data:\n",
    "      io_binding.bind_ortvalue_input(k, data_ortvalue[k])\n",
    "\n",
    "  output_tokens = []\n",
    "  for i in range(TOKENS_PER_FRAME):\n",
    "    if i == 0 and override is not None:\n",
    "      output_tokens.append([[override]])\n",
    "      continue\n",
    "\n",
    "    io_binding.bind_output('logits', 'cuda')\n",
    "    \n",
    "    for j in range(24):\n",
    "      io_binding.bind_output(f'present_{j}', 'cuda')  \n",
    "\n",
    "    session.run_with_iobinding(io_binding)\n",
    "    ort_output = io_binding.get_outputs()  \n",
    "\n",
    "    logits = ort_output[0].numpy()[:,-1,:]\n",
    "    logits = logits.astype(np.float64)\n",
    "    probs = softmax(logits, axis=1)\n",
    "    tokens = multinomial(probs).astype(np.int32)\n",
    "        \n",
    "    output_tokens.append(tokens)\n",
    "    data_ortvalue['input_ids'] = ort.OrtValue.ortvalue_from_numpy(tokens, 'cuda', 0)\n",
    "    io_binding.bind_ortvalue_input('input_ids', data_ortvalue['input_ids'])\n",
    "\n",
    "    for j in range(24):\n",
    "      io_binding.bind_ortvalue_input(f'past_{j}', ort_output[1+j])\n",
    "  \n",
    "  return np.concatenate(output_tokens, axis=1)\n",
    "\n",
    "sg_width = PIXELS_PER_CHUNK\n",
    "shift_gradient = np.zeros((128, sg_width), dtype=np.float32)\n",
    "for i in range(sg_width):\n",
    "    shift_gradient[:, i] = float(i) / float(sg_width)\n",
    "\n",
    "def save_frame(tokens_gen, img_name, upscale=True):\n",
    "    output = decoder_session.run(None, {'encoding_indices': tokens_gen[-1].reshape(1,8,16)})\n",
    "    output = {o.name: x for o,x in zip(decoder_session.get_outputs(), output)}\n",
    "    output = output['big_decoded_img']\n",
    "\n",
    "    frame_path = f\"../tmp/{img_name}\"\n",
    "    if not os.path.exists(os.path.dirname(frame_path)):\n",
    "        os.makedirs(os.path.dirname(frame_path))\n",
    "    decoded_frame = transpose_and_clip([output])[0]\n",
    "    cv2.imwrite(frame_path, decoded_frame)\n",
    "    if upscale:\n",
    "        img = cv2.imread(frame_path)\n",
    "        img = cv2.resize(img, (1280, int(1280*img.shape[0]/img.shape[1])))\n",
    "        cv2.imwrite(frame_path, img)\n",
    "\n",
    "def shift_right(tokens_gen):\n",
    "    for i in range(tokens_gen.shape[2] - 1):\n",
    "        tokens_gen[0, :, i] = tokens_gen[0, :, i + 1]\n",
    "def shift_left(tokens_gen):\n",
    "    for i in range(tokens_gen.shape[2] - 1, 0, -1):\n",
    "        tokens_gen[0, :, i] = tokens_gen[0, :, i - 1]\n",
    "\n",
    "def turn_gen(tokens_gen, shift_func):\n",
    "    tmp_path = \"../tmp/temp.png\"\n",
    "    save_frame(tokens_gen, tmp_path, upscale=False)\n",
    "    img_orig = cv2.imread(tmp_path)\n",
    "    shift_func(tokens_gen)\n",
    "    save_frame(tokens_gen, tmp_path, upscale=False)\n",
    "    img_turn = cv2.imread(tmp_path)\n",
    "    return img_orig, img_turn\n",
    "def encode_turn(img):\n",
    "    outputs = encoder_session.run(None, {'big_img': img.transpose(2,0,1)[None].astype(np.float32)})\n",
    "    outputs = {o.name: x for o,x in zip(encoder_session.get_outputs(), outputs)}\n",
    "    return outputs['encoding_indices'].ravel()\n",
    "\n",
    "def turn_left(tokens_gen, shift_amount):\n",
    "    assert shift_amount > 0 and shift_amount < PIXELS_PER_CHUNK\n",
    "    img_orig, img_turn = turn_gen(tokens_gen, shift_right)\n",
    "\n",
    "    img_orig[:, shift_amount:] = img_orig[:, :-shift_amount]\n",
    "    img_orig[:, :shift_amount] = img_turn[:, PIXELS_PER_CHUNK-shift_amount:PIXELS_PER_CHUNK]\n",
    "    for c in range(3):\n",
    "        img_orig[:, shift_amount:shift_amount+PIXELS_PER_CHUNK, c] = \\\n",
    "            img_orig[:, shift_amount:shift_amount+PIXELS_PER_CHUNK, c] * shift_gradient + \\\n",
    "            img_turn[:, PIXELS_PER_CHUNK:2*PIXELS_PER_CHUNK, c] * (1 - shift_gradient)\n",
    "    return encode_turn(img_orig)\n",
    "\n",
    "def turn_right(tokens_gen, shift_amount):\n",
    "    assert shift_amount > 0 and shift_amount < PIXELS_PER_CHUNK\n",
    "    img_orig, img_turn = turn_gen(tokens_gen, shift_left)\n",
    "\n",
    "    img_orig[:, :-shift_amount] = img_orig[:, shift_amount:]\n",
    "    img_orig[:, -shift_amount:] = img_turn[:, -PIXELS_PER_CHUNK:-PIXELS_PER_CHUNK+shift_amount]\n",
    "    for c in range(3):\n",
    "        img_orig[:, -shift_amount-PIXELS_PER_CHUNK:-shift_amount, c] = \\\n",
    "            img_orig[:, -shift_amount-PIXELS_PER_CHUNK:-shift_amount, c] * shift_gradient + \\\n",
    "            img_turn[:, -2*PIXELS_PER_CHUNK:-PIXELS_PER_CHUNK, c] * (1 - shift_gradient)\n",
    "    return encode_turn(img_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNER\n",
    "\n",
    "# load tokens\n",
    "tokens_condition = np.load(\"../examples/tokens.npy\").astype(np.int32)\n",
    "tokens_condition = np.c_[np.ones(len(tokens_condition), dtype=np.int32)*BOS_TOKEN, tokens_condition]\n",
    "tokens_condition = tokens_condition[-(MAX_CONTEXT_SIZE//TOKENS_PER_FRAME - 1):].reshape(1,-1)\n",
    "\n",
    "frames = []\n",
    "\n",
    "movement = 0\n",
    "frame_count = 0\n",
    "while True:\n",
    "    tokens = generate_frame_tokens(session, tokens_condition[:, -(MAX_CONTEXT_SIZE-TOKENS_PER_FRAME):])\n",
    "    tokens_condition = np.concatenate([tokens_condition, tokens], axis=1)\n",
    "\n",
    "    # reshape and remove BOS token\n",
    "    tokens_gen = tokens.reshape(-1,TOKENS_PER_FRAME)\n",
    "    tokens_gen = tokens_gen[:, 1:].astype(np.int64)\n",
    "    tokens_gen = tokens_gen[-1].reshape(1,8,16)\n",
    "\n",
    "    def apply_turn_left(turn_amount):\n",
    "        new_state = turn_left(tokens_gen, turn_amount)\n",
    "        tokens_condition[0, -TOKENS_PER_FRAME+1:] = new_state.astype(np.int32).reshape(1,-1)\n",
    "        return new_state\n",
    "    def apply_turn_right(turn_amount):\n",
    "        new_state = turn_right(tokens_gen, turn_amount)\n",
    "        tokens_condition[0, -TOKENS_PER_FRAME+1:] = new_state.astype(np.int32).reshape(1,-1)\n",
    "        return new_state\n",
    "    \n",
    "    if movement < 0:\n",
    "        tokens_gen = apply_turn_left(-movement)\n",
    "    elif movement > 0:\n",
    "        tokens_gen = apply_turn_right(movement)\n",
    "    \n",
    "    # reshape and remove BOS token\n",
    "    tokens_gen = tokens.reshape(-1,TOKENS_PER_FRAME)\n",
    "    tokens_gen = tokens_gen[:, 1:].astype(np.int64)\n",
    "    tokens_gen = tokens_gen[-1].reshape(1,8,16)\n",
    "\n",
    "    output = decoder_session.run(None, {'encoding_indices': tokens_gen})\n",
    "    output = {o.name: x for o,x in zip(decoder_session.get_outputs(), output)}\n",
    "    output = output['big_decoded_img']\n",
    "    frames.append(output)\n",
    "\n",
    "    frame_path = \"../tmp/frame.png\"\n",
    "    if not os.path.exists(os.path.dirname(frame_path)):\n",
    "        os.makedirs(os.path.dirname(frame_path))\n",
    "    decoded_frame = transpose_and_clip([output])[0]\n",
    "\n",
    "    cv2.imwrite(frame_path, decoded_frame)\n",
    "    img = cv2.imread(frame_path)\n",
    "    img = cv2.resize(img, (1280, int(1280*img.shape[0]/img.shape[1])))\n",
    "    cv2.putText(img, str(frame_count), (10,30), cv2.FONT_ITALIC, 1, (0,0,255), 2)\n",
    "    frame_count += 1\n",
    "    cv2.imwrite(frame_path, img)\n",
    "\n",
    "    if keyboard.is_pressed(\"q\"):\n",
    "        break\n",
    "    if keyboard.is_pressed(\"left\"):\n",
    "        movement = -2\n",
    "    elif keyboard.is_pressed(\"right\"):\n",
    "        movement = 2\n",
    "    else:\n",
    "        movement = 0\n",
    "\n",
    "if len(frames) > 20:\n",
    "    decoded_video = transpose_and_clip(frames)\n",
    "    save_dst = '../tmp/generated.mp4'\n",
    "    write_video(decoded_video, save_dst, fps=20)    \n",
    "    Video(save_dst, embed=True, width=700)\n",
    "\n",
    "######################\n",
    "# Key   | Action     #\n",
    "# ================== #\n",
    "# left  | turn left  #\n",
    "# right | turn right #\n",
    "# q     | quit       #\n",
    "######################\n",
    "\n",
    "# The frames will be generated at ../tmp/frame.png\n",
    "# The controls should work OS wide, I launch this block, open the\n",
    "# generated frame in a VSCode tab, and can control the \"car\" from there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
